<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>Project: Data Processing Layer in O2 Framework</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../o2_logo.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="../../index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="../../pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="../../modules.html"><span>Modules</span></a></li>
      <li><a href="../../namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="../../annotated.html"><span>Classes</span></a></li>
      <li><a href="../../files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="../../search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('d1/dad/md__home_travis_build_AliceO2Group_AliceO2_Framework_Core_README.html','../../');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(12)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Data Processing Layer in O2 Framework </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Status quo and motivation for an O2 Data Processing Layer</h2>
<p>FairMQ currently provides a well documented and flexible framework for an actor based computation where each of the actors listens for message-like entities on channels and executes some code as a reaction. The key component which controls this is called a <code><a class="el" href="../../db/dfe/classFairMQDevice.html">FairMQDevice</a></code> (or <em>device</em> from now on) which can use different kind of transports to receive and send messages. In the most generic case, users are allowed to have full control on the state machine governing the message passing and have complete control on how the message handling is done. This of course covers all ALICE usecases in a generic manner, at the cost of extra complexity left to the user to implement. In most cases however a simplified way of creating devices is provided, and the user will simply create its own <code><a class="el" href="../../db/dfe/classFairMQDevice.html">FairMQDevice</a></code>-derived class, which registers via the <code>OnData(FairMQParts &amp;parts)</code> method a callback that is invoked whenever a new message arrives. This however still holds the user responsible for:</p>
<ul>
<li>Verifying that the required inputs for the computation are all available, both from the actual data flow (being it for readout, reconstruction or analysis) and from the asynchronous stream (e.g. alignment and calibrations).</li>
<li>Create the appropriate message which holds the results and send it.</li>
<li>Ensure the ease of testability, the code reuse and the proper documentation <code>OnData</code> callback. In particular there is no way to inspect which data is expected by a device and which data is produced.</li>
</ul>
<p>This is by design, because the FairMQ transport layer should not know anything about the actual data being transferred, while all the points above require some sort of inner knowledge about the data model and the data being moved around.</p>
<p>The aim is to achieve the following:</p>
<ul>
<li><b>Explicit data flow:</b> Input and outputs are declared upfront and can be used for documentation or for automatic topology creation (assuming the actual processing environment is known).</li>
<li><b>Transport agnostic data processing:</b> users will not have to know about the details of how the data materialises on their device, they will always be handed the full set of payloads they requested, even if they come at different time.</li>
<li><b>Composability of data processing:</b> different process functions can in principle be chained and scheduled together depending on the desired granularity for devices.</li>
</ul>
<h2>Separating data-processing from transport</h2>
<p>For the reasons mentioned above, we propose that the one of the developments which should happen with the O2 Framework work package is the development of a “Data Processing layer” which actually knows about the O2 Data Model (and for this reason cannot be part of FairMQ itself) and exploits it to validate, optimise and correctly schedule a computation on a user specified set of inputs.</p>
<p>The Data Processing Layer in particular requires:</p>
<ul>
<li>That the inputs of each computation are provided upfront.</li>
<li>That the outputs of each computation are provided upfront.</li>
<li>That a time identifier can be associated to inputs</li>
</ul>
<p>and given these premises it actually guarantees:</p>
<ul>
<li>That no computation is performed before all the inputs for a given time identifier are available</li>
<li>That no message passing happens during the performing of the computation, but uniquely at the end.</li>
</ul>
<h3>Instanciating a computation</h3>
<p>The description of the computation in such the Data Processing Layer is done via instances of the <a href="https://github.com/AliceO2Group/AliceO2/blob/dev/Framework/Core/include/Framework/DataProcessorSpec.h">`DataProcessorSpec`</a> class, grouped in a so called <code>WorkflowSpec</code> instance. In order to provide a description a computation to be run, the user must implement a callback which modifies an empty <code>WorkflowSpec</code> instance provided by the system. E.g.: </p>
<pre class="fragment">#include "Framework/Utils/runDataProcessing.h"

void defineDataProcessing(WorkflowSpec &amp;workflow) {
  auto spec = DataProcessorSpec{
    ...
  };
  // Fill a DataProcessingSpec "spec"
  workflow.push_back(spec);
}
</pre><p>See next section, for a more detailed description of the <a href="https://github.com/AliceO2Group/AliceO2/blob/dev/Framework/Core/include/Framework/DataProcessorSpec.h">`DataProcessorSpec`</a> class. The code above has to be linked into a single executable together with the Data Processing Layer code to form a so called driver executable which if run will:</p>
<ul>
<li>Map all <a href="https://github.com/AliceO2Group/AliceO2/blob/dev/Framework/Core/include/Framework/DataProcessorSpec.h">`DataProcessorSpec`</a> to a set of <code><a class="el" href="../../db/dfe/classFairMQDevice.html">FairMQDevice</a></code>s (using 1-1 correspondence, in the current implementation).</li>
<li>Instanciate and start all the devices resulted from the previous step.</li>
<li>(Optionally) start a GUI which allows to monitor the running of the system.</li>
</ul>
<p>#</p>
<h2>Describing a computation</h2>
<p>The description of the computation in such a layer is done via a <code>DataProcessorSpec</code> class, which describes some sort of processing of a (set of) O2 Data Payloads (<em>payloads</em> from now on), as defined by the O2 Data Model, eventually producing new payloads as outputs. The inputs to the computation, the outputs and the actual code to run on the former to produce the latter, is specified in a <code>DataProcessorSpec</code> instance. Multiple <code>DataProcessorSpec</code> instances can be grouped together in a <code>WorkflowSpec</code>. to the driver code which maps configures the processing device accordingly. Practically speaking this would translate into something similar to the current “simplified device mode” where the user includes a special header which contains all the boilerplate and provides a well defined callback where the requested <code>DataProcessorSpec</code> are provided.</p>
<p>The <code>DataProcessorSpec</code> is defined as follows: </p>
<pre class="fragment">struct DataProcessorSpec {
   using InitCallback = std::function&lt;ProcessCallback(InitContext &amp;)&gt;;
   using ProcessCallback = std::function&lt;void(ProcessingContext &amp;)&gt;;
   using ErrorCallback = std::function&lt;void(ErrorContext &amp;)&gt;;
   std::vector&lt;InputSpec&gt; inputs;
   std::vector&lt;OutputSpec&gt; outputs;
   std::vector&lt;ConfigParamSpec&gt; configParams;
   std::vector&lt;std::string&gt; requiredServices;
   AlgorithmSpec algorithm;
};
</pre><p>In the above both <code>InputSpec</code> and <code>OutputSpec</code> are like: </p>
<pre class="fragment">struct InputSpec {              // OutputSpec as well
  o2::Headers::DataDescription description;
  o2::Headers::DataOrigin origin;
  o2::Headers::SubSpecificationType subSpec;
  enum Lifetime lifetime;
};
</pre><p>where description, origin and subSpec match the O2 Data Model definition. For the moment we will consider this a one to one mapping with the <code>o2::Headers::DataHeader</code> ones. In principle one could think of a one-to-many relationship (e.g. give me all the clusters, regardless of their provenance) and the processing layer could automatically aggregate those in a unique view. This is also the semantic difference between <code>InputSpec</code> and <code>OutputSpec</code>: the former is to express data that matches a given query (which must be exact at the moment) the latter is to describe in all details and without any doubt the kind of the produced outputs.</p>
<p>The <code>lifetime</code> property: </p>
<pre class="fragment">enum Lifetime {
  Timeframe,
  Condition,
  QA,
  Transient
};
</pre><p>can be used to distinguish if the associated payload should be considered payload data, and therefore be processed only once, or alignment / conditions data, and therefore it would be considered valid until a new copy is made available to the device.</p>
<p>The <code>configParams</code> vector would be used to specify which configuration options the data processing being described requires: </p>
<pre class="fragment">struct ConfigParamSpec {
  std::string name;
  enum ParamType type;
  variant defaultValue;
};
</pre><p>command line / configuration options would be automatically generated by it. These are available only at init stage, and can be used to configure services. They are not available to the actual <code>process</code> callback as all the critical parameters for data processing should be part of the data stream itself, eventually coming from CCDB / ParameterManager.</p>
<p>Similarly the <code>requiredServices</code> vector would define which services are required for the data processing. For example this could be used to declare the need for some data cache, a GPU context, a thread pool.</p>
<p>The <code>algorithm</code> property, of <code>AlgorithmSpec</code> is instead used to specify the actual computation. Notice that the same <code>DataProcessorSpec</code> can used different <code>AlgorithmSpec</code>. The rationale for this is that while inputs and outputs might be the same, you might want to compare different versions of your algorithm. The <code>AlgorithmSpec</code> resembles the following: </p>
<pre class="fragment">struct AlgorithmSpec {
  using ProcessCallback = std::function&lt;void(ProcessingContext &amp;)&gt;;
  using InitCallback = std::function&lt;ProcessCallback(InitContext &amp;)&gt;;
  using ErrorCallback = std::function&lt;void(ErrorContext &amp;)&gt;;

  InitCallback onInit = nullptr;
  ProcessCallback onProcess = nullptr;
  ErrorCallback onError = nullptr;
};
</pre><p>The <code>onProcess</code> function is to be used for stateless computations. It’s a free function and it’s up to the framework to make sure that all the required components are declared upfront. It takes as input the context for the current computation in the form of a <code>ProcessingContext &amp;</code> instance. Such a context consist of:</p>
<ul>
<li>An <code>InputRecord</code> which allows retrieving the current inputs matching the provided specification.</li>
<li>A <code>ServiceRegistry</code> referencing the set of services it declared as required the computation.</li>
<li>A <code>DataAllocator</code> allocator which can allocate new payloads only for the types which have been declared as <code>outputs</code>.</li>
</ul>
<p><code>onProcess</code> is useful whenever your computation is fully contained in your input. In several cases, however, a computation requires some ancillary state, which needs to be initialised only on (re-)start of the job. For example you might want to initialise the geometry of your detector. To do so, you can use the <code>onInit</code> callback and allocate the state and pass it to the returned <code>ProcessCallback</code> as captured arguments. E.g: </p>
<pre class="fragment">AlgorithmSpec{
  InitCallBack{[](InitContext &amp;setup){
      auto statefulGeo = std::make_shared&lt;TGeo&gt;();
      return [geo = statefulGeo](ProcessingContext &amp;) {
        // do something with geo
      };
    }
  }
}
</pre><p>A <code>DataRef</code> would look like: </p>
<pre class="fragment">struct DataRef {
  const InputSpec *spec;
  const char *const header;
  const char *const payload;
};
</pre><p><code>header</code> and <code>payload</code> are the pointers to the data which matches the <code>spec</code> InputSpec.</p>
<h2>Implementing a computation</h2>
<p>This chapter describes how to actually implement an <code>AlgorithmSpec</code>.</p>
<h3>Using inputs - the <code>InputRecord</code> API</h3>
<p>Inputs to your computation will be provided to you via the <a href="https://github.com/AliceO2Group/AliceO2/blob/HEAD/Framework/Core/include/Framework/InputRecord.h">`InputRecord`</a> API. An instance of such a class is hanging from the <code>ProcessingContext</code> your computation lambda is passed and contains one value for each of the <code>InputSpec</code> you specified. E.g.: </p>
<pre class="fragment">InputRecord &amp;args = ctx.inputs();
</pre><p>From the <code>InputRecord</code> instance you can get the arguments either via their positional index: </p>
<pre class="fragment">DataRef ref = args.getByPos(0);
</pre><p>or using the mnemonics-label which was used as first argument in the associated <code>InputSpec</code>. </p>
<pre class="fragment">DataRef ref = args.get("points");
</pre><p>You can then use the <code>DataRef</code> <code>header</code> and <code>payload</code> raw pointers to access the data in the messages.</p>
<p>If the message is of a known type, you can automatically get a casted reference to the contents of the message by passing it as template argument, e.g.: </p>
<pre class="fragment">XYZ &amp;p = args.get&lt;XYZ&gt;("points");
</pre><p>#</p>
<h2>Creating outputs - the DataAllocator API</h2>
<p>In order to prevent algorithms to create data they do are not supposed to create, a special <code>DataAllocator</code> object is passed to the process callback, so that only messages for declared outputs can be created. A <code>DataAllocator</code> can create Framework owned resources via the <code>make&lt;T&gt;</code> method. In case you ask the framework to create a collection of objects, the result will be a <code>gsl::span</code> wrapper around the collection. A <code>DataAllocator</code> can adopt externally created resources via the <code>adopt</code> method. A <code>DataAllocator</code> can create a copy of an externally owned resource via the <code>snapshot</code> method.</p>
<p>Currently supported data types are:</p>
<ul>
<li>Vanilla <code>char *</code> buffers with associated size. This is the actual contents of the FairMQ message.</li>
<li>POD types. These get directly mapped on the message exchanged by FairMQ and are therefore "zerocopy" for what the DataProcessingLayer is concerned.</li>
<li>POD collections, which are exposed to the user as <code>gsl::span</code>.</li>
<li>TObject derived classes. These are actually serialised via a <a class="el" href="../../d9/dc7/classTMessage.html">TMessage</a> and therefore are only suitable for the cases in which the cost of such a serialization is not an issue.</li>
</ul>
<p>The DataChunk object resembles a <code>iovec</code>: </p>
<pre class="fragment">struct DataChunk {
  char *data;
  size_t size;
};
</pre><p>however, no API is provided to explicitly send it. All the created DataChunks are sent (potentially using scatter / gather) when the <code>process</code> function returns. This is to avoid the “modified after send” issues where a message which was sent is still owned and modifiable by the creator.</p>
<h3>Error handling</h3>
<p>When an error happens during processing of some data, the writer of the <code>process</code> function should simply throw an exception. By default the exception is caught by the <code>DataProcessorManager</code> and a message is printed (if <code>std::exeception</code> derived <code>what()</code> method is used, otherwise a generic message is given). Users can provide themselves an error handler by specifying via the <code>onError</code> callback specified in <code>DataProcessorSpec</code>.</p>
<h3>Services</h3>
<p>Services are utility classes which <code>DataProcessor</code>s can access to request out-of-bound, deployment dependent, functionalities. For example a service could be used to post metrics to the monitoring system or to get a GPU context. The former would be dependent on whether you are running on your laptop (where monitoring could simply mean print out metrics on the command line) or in a large cluster (where monitoring probably means to send metrics to an aggregator device which then pushes them to the backend.</p>
<p>Services are initialised by the driver code (i.e. the code included via runDataProcessing.h) and passed to the user code via a <code>ServiceRegistry</code>. You can retrieve the service by the type of its interface class. E.g. for monitoring you can do: </p>
<pre class="fragment">#include "Framework/MetricsService.h"
...
auto service = ctx.services().get&lt;MetricsService&gt;(); // In the DataProcessor lambda...
service.post("my/metric", 1); ...
</pre><p>Currently available services are described below.</p>
<h4>ControlService</h4>
<p>The control service allow DataProcessors to modify their state or the one of their peers in the topology. For example if you want to quit the whole data processing topology, you can use: </p>
<pre class="fragment">#include "Framework/ControlService.h"
...
auto ctx.services().get&lt;ControlService&gt;().readyToQuit(true) // In the DataProcessor lambda
</pre><h4>RawDeviceService</h4>
<p>This service allows you to get an hold of the <code><a class="el" href="../../db/dfe/classFairMQDevice.html">FairMQDevice</a></code> running the DataProcessor computation from with the computation itself. While in general this should not be used, it is handy in case you want to integrate with a pre-existing <code><a class="el" href="../../db/dfe/classFairMQDevice.html">FairMQDevice</a></code> which potentially does not even follow the O2 Data Model.</p>
<h2>Miscellaneous topics</h2>
<h3>Debugging on your laptop</h3>
<p>The way the DPL currently works is that the driver executable you launch, will then take care of spawning one device per <code>DataProcessorSpec</code> in a separate process. This means that in order to debug your code you need to make sure gdb / lldb are actually debugging the right child process.</p>
<p>For <code>gdb</code> you can use the <code>follow-fork-mode</code> setting. See <a href="https://sourceware.org/gdb/onlinedocs/gdb/Forks.html">here</a> for the full documentation. This is unfortunately not available in <a href="https://bugs.llvm.org/show_bug.cgi?id=17972">lldb</a>.</p>
<p>Alternatively you can start your driver executable with the <code>-s</code> / <code>--stop</code> command line option which will immediately stop execution of the children after the fork, allowing you to attach to them, e.g. for gdb using:</p>
<p>attach &lt;pid&gt;</p>
<p>or the <code>lldb</code> equivalent:</p>
<p>attach -pid &lt;pid&gt;</p>
<h3>Expressing parallelism</h3>
<p>If we want to retain a message passing semantic and really treat shared memory as yet another transport, we need to be very careful in how to express parallelism on data, so that the “single ownership model” of message passing forces us to either duplicate streams that need to be accessed in parallel, or to serialise workers which need to access the same data. Solutions like reference counting shared memory would not be allowed in such a scenario and in any case would require extra caution and support to make sure that failures do not leave dangling reference around (e.g. when one of the parallel workers abruptly terminates). First of all let’s consider the fact that there are two level of parallelisms which can be achieved:</p>
<ul>
<li>Data flow parallelism: when data can be split in partitions according to some subdivision criteria (e.g. have one stream per TPC sector and have one worker for each).</li>
<li>Time flow parallelism: when parallelism can be achieved by having different workers handle different time intervals for the incoming data. (e.g. worker 0 processes even timeframes, worker 1 processes odd timeframes).</li>
</ul>
<p>Data flow parallelism is simply expressed by tuning the data flow, adding explicitly the parallel data paths, using the appropriate <code>InputSpec</code> and <code>OutputSpec</code>. E.g.: </p>
<pre class="fragment">DataProcessorSpec{
  "tpc_processor_1",
  Inputs{},
  Outputs{{"TPC", "CLUSTERS", SubSpec(0)}},
  ...
},
DataProcessorSpec{
  "tpc_processor_2",
  Inputs{},
  Outputs{{"TPC", "CLUSTERS", SubSpec(1)}},
  ...
}
...
DataProcessorSpec{
  "tpc_processor_18",
  Inputs{},
  Outputs{{"TPC", "CLUSTERS", SubSpec(17)}},
  ...
}
</pre><p>or alternatively the parallel workflows part could be generated programmatically:</p>
<pre class="fragment">parallel(
  DataProcessorSpec{
    "tpc_processor",
    {InputSpec{"c", "TPC", "CLUSTERS"}}
  },
  18,
  [](DataProcessorSpec &amp;spec, size_t idx) {
    spec.outputs[0].subSpec = idx; // Each of the 18 DataProcessorSpecs should have a different subSpec
  }
)
</pre><p>Similarly this can be done for a component that merges inputs from multiple parallel devices, this time by modifying programmatically the <code>Inputs</code>: </p>
<pre class="fragment">...
DataProcessorSpec{
  "merger",
  mergeInputs({"a", "TST", "A", InputSpec::Timeframe},
              4,
              [](InputSpec &amp;input, size_t index) {
                 input.subSpec = index;
              }
          ),
  {},
  AlgorithmSpec{[](InitContext &amp;setup) {
     return [](ProcessingContext &amp;ctx) {
  // Create a single output.
    LOG(DEBUG) &lt;&lt; "Invoked" &lt;&lt; std::endl;
  };
}
...
</pre><p>When one declares a parallel set of devices you can retrieve the rank (i.e. parallel id) or the number of parallel devices by using the <code>ParalleContext</code>, which can be retrieved from the <code>ServiceRegistry</code> (see also the <code>Services</code> section below), e.g.: </p>
<pre class="fragment">size_t whoAmI = services.get&lt;ParallelContext&gt;().index1D();
size_t howManyAreWe = services.get&lt;ParallelContext&gt;().index1DSize();
</pre><p>A second type of parallelism is time based pipelining. This assumes that the data can be subdivided in subsequent "time periods" that are independent one from the other and which are each identified by some timestamp entity. In this particular case it could result handy that some part of the workflow are actually processing different time periods. This can be expressed via the <code>timePipeline</code>, directive, e.g.: </p>
<pre class="fragment">...
timePipeline(DataProcessorSpec{
  "processor",
  {InputSpec{"a", "TST", "A"}},
  {OutputSpec{"TST", "B"}},
  AlgorithmSpec{[](ProcessingContext &amp;ctx) {
    };
  }
}, 2);
...
</pre><p>which will result in two devices, one for even time periods, the other one for odd timeperiods.</p>
<h3>Debug GUI</h3>
<p>The demonstator also includes a simple GUI to help debugging problems:</p>
<div class="image">
<img src="https://user-images.githubusercontent.com/10544/29307499-75bb8550-81a2-11e7-9aa6-96b7613288b5.png" />
</div>
<p>The GUI provides the following facilities:</p>
<ul>
<li>Graph view with all the connections between DataProcessors</li>
<li>One log window per DataProcessor, allowing filtering and triggering on log messages</li>
<li>Metrics inspector</li>
</ul>
<h3>Integrating with pre-existing devices</h3>
<p>Given the Data Processing Layer comes somewhat later in the design of O2, it's possible that you already have some topology of devices which you want to integrate, without having to port them to the DPL itself. Alternatively, your devices might not satisfy the requirements of the Data Processing Layer and therefore require a "raw" <code><a class="el" href="../../db/dfe/classFairMQDevice.html">FairMQDevice</a></code>, fully customised to your needs. This is fully supported and we provide means to ingest foreign, non-DPL FairMQDevices produced, messages into a DPL workflow. This is done via the help of a "proxy" data processor which connects to the foreign device, receives its inputs, optionally converts them to a format understood by the Data Processing Layer, and then pumps them to the right Data Processor Specs. In order to have such a device in your workflow, you can use the <a href="https://github.com/AliceO2Group/AliceO2/blob/dev/Framework/Core/include/Framework/ExternalFairMQDeviceProxy.h">`specifyExternalFairMQDeviceProxy`</a> helper to instanciate it. For an example of how to use it you can look at <a href="https://github.com/AliceO2Group/AliceO2/blob/dev/Framework/TestWorkflows/src/test_RawDeviceInjector.cxx">`Framework/TestWorkflows/src/test_RawDeviceInjector.cxx`</a>. The <code>specifyExternalFairMQDeviceProxy</code> takes four arguments: </p>
<pre class="fragment">specifyExternalFairMQDeviceProxy("foreign-source",
                {outspec},
                "type=sub,method=connect,address=tcp://localhost:5450,rateLogging=1",
                o2DataModelAdaptor(outspec, 0, 1)
               ),
</pre><p>the first one is the usual <code>DataProcessorSpec</code> name, the second one is a list of outputs which we will create from the non-DPL device, the third one is a string to connect to the existing topology and a the fourth one is a function of the kind <code><a class="el" href="../../dd/d8d/namespaceo2_1_1framework.html#a3b5eaeeac30d9e8e328f8cb1095938cc">o2::framework::InjectorFunction</a></code> which does the actual conversion. In this particular case we use the <code><a class="el" href="../../dd/d8d/namespaceo2_1_1framework.html#a8c5da815907e3670cb170bc9132c3723">o2DataModelAdaptor()</a></code> helper to create such an translation function since we know that our input is already respecting the O2 Data Model and most of the heavylifing can be done automatically.</p>
<p>Sending out the results of a computation can be done in a similar manner. Use </p>
<pre class="fragment">ConfigParamSpec{"channel-config", VariantType::String, "&lt;channel-configuration&gt;", "Out-of-band channel config"}
</pre><p>to create an out-of-band channel as specified in <code>channel-configuration</code> and then use the <code>RawDeviceService</code> to get the raw <a class="el" href="../../db/dfe/classFairMQDevice.html">FairMQDevice</a> and send data through such a channel.</p>
<p>#</p>
<h1>Current Demonstrator (WIP)</h1>
<p>An demonstrator illustrating a possible implementation of the design described above is now found in the dev branch of AliceO2, in the <a href="https://github.com/AliceO2Group/AliceO2/tree/dev/Framework">Framework</a> folder. In particular:</p>
<ul>
<li><code>Framework/Core</code> folder contains the <code>DataProcessorSpec</code> class and related.</li>
<li><code>Framework/Core/test</code> folder contains a few unit test and simple example workflows.</li>
<li><code>Framework/TestWorkflows</code> folder contains a few example workflows.</li>
<li><code>Framework/DebugGUI</code> folder contains the core GUI functionalities.</li>
</ul>
<h2>Interesting reads</h2>
<ul>
<li><a href="https://research.google.com/pubs/pub41378.html">MillWheel: Fault-Tolerant Stream Processing at Internet Scale</a> : paper about Google previous generation system for stream processing</li>
<li><a href="http://concord.io">Concord</a> : Similar (to the above) stream processing solution, OpenSource.</li>
</ul>
<h2>General remarks &amp; Feedback so far:</h2>
<ul>
<li>Gvozden and Mikolaj were suggesting to have a multiple payload view-like object. Where does that fit? Shouldn’t this feature be provided by the DataRef binder?</li>
<li>Do we need <code>process</code> to return a <code>bool</code> / an <code>error</code> code?</li>
<li>What are the possible Services we can think about?<ul>
<li>CPUTimer</li>
<li>File Reader</li>
<li>File Writer</li>
<li>Monitoring</li>
<li>Logging</li>
<li>ParallelContext</li>
</ul>
</li>
<li>Thorsten: should configuration come always from the ccdb?</li>
<li>Thorsten: should allow to specify that certain things are processed with the same CCDB conditions.</li>
<li>Should we have different specifications for conditions objects and for data?<ul>
<li>We could simplify current design by making Timeframe the default.</li>
<li>It complicates a bit the <code>process</code> method. We would need an extra allocator for the output objects and we would need an extra vector for the inputs.</li>
<li>On the other hand it would probably make some of the flow code easier to read / more type safe.</li>
</ul>
</li>
<li>Can inputs / outputs be optional? Most likely, no, since that would mean that if they arrive late the processing happens with a different set of inputs (and consequently a optional output means someone has an optional input). Do we need some “guaranteed delivery” for messages?</li>
<li>~~Do we need to guarantee that timeframes are processed in their natural order?~~ nope. Actually in general we cannot guarantee that.</li>
<li>Do we want to separate “Algorithms”s from “DataProcessor”s? The former would declare generic argument bindings (e.g. I take x, and y) and the latter would do the actual binding to real data (input clusters is y, input tracks is y). This is what tensor flow actually does.</li>
<li>Shouldn’t the DataHeader contain the timeframe ID?</li>
<li>David / Ruben: sometimes the input data depends on whether or not a detector is active during data taking. We would therefore need a mechanism to mask out inputs (and maybe modules) from the dataflow, based on run control. If only part of the data is available, it might make sense that we offer “fallback” callbacks which can work only on part of the data.</li>
<li>Ruben: most likely people will want to also query the CCDB directly. Does it make sense to offer CCDB querying as a service so that we can intercept (and eventually optimise) multiple queries from the same workflow?</li>
<li>Are options scoped? I.e. do we want to have that if two devices, <code>deviceA</code> and <code>deviceB</code> defining the same option (e.g. <code>mcEngine</code>) they will require / support using <code>--</code><code>deviceA-mcEngine</code> and <code>--</code><code>deviceB-mcEngine</code>?</li>
<li>~~Mikolaj pointed out that capture by move is possible in <code>C++14</code> lambdas, so we should use that for the stateful init~~. Actually this is not working out as expected? </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Dec 14 2017 06:51:52 for Project by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="../../doxygen.png" alt="doxygen"/></a> 1.8.6 </li>
  </ul>
</div>
</body>
</html>
